{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1246668,"sourceType":"datasetVersion","datasetId":715814},{"sourceId":8637787,"sourceType":"datasetVersion","datasetId":5172695}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport warnings; warnings.simplefilter('ignore')\nimport nltk\nimport re\nimport string\nfrom string import punctuation\nfrom nltk import ngrams\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the datasets\n\ndf_train = pd.read_csv(\"/kaggle/input/drug-dataset/drugsComTrain_raw.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/drug-dataset/drugsComTest_raw.csv\") \n\nprint (\"The shape of the train set given is : \", df_train.shape)\nprint (\"The shape of the test set given is : \", df_test.shape)\n\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[df_train['condition'].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dropna(subset=['condition'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating what percentage of data is null\nsize = df_train.shape[0]\n\nprint (\"Total Size of the dataset : \", size)\n\ntotal_na = df_train.isnull().sum(axis = 0)['condition']\nprint (\"Null values : \", total_na)\n\nprint (\"PERCENTAGE : \", (total_na/size)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the data points with null values as it's very much less than 5% of the whole dataset\ndf_data = df_train.dropna(how = 'any', axis = 0)\n\nprint (\"The shape of the dataset after null values removal :\", df_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data.sort_values(['uniqueID'], ascending = True, inplace = True)\ndf_data.reset_index(drop = True, inplace = True)\ndf_data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the date in to date time format \ndf_data['date'] = pd.to_datetime(df_data['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data['rating'].unique().tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Giving the Sentiment according to the ratings\ndf_data['sentiment_rate'] = df_data['rating'].apply(lambda x: 1 if x > 5 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data['sentiment_rate'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.899891Z","iopub.execute_input":"2024-06-08T12:04:55.900162Z","iopub.status.idle":"2024-06-08T12:04:55.908382Z","shell.execute_reply.started":"2024-06-08T12:04:55.900130Z","shell.execute_reply":"2024-06-08T12:04:55.907499Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"sentiment_rate\n1    112611\n0     47787\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_data_1_sampled = df_data[df_data['sentiment_rate'] == 1].sample(n=47787, random_state=42)\ndf_data_0 = df_data[df_data['sentiment_rate'] == 0]\ndf_balanced = pd.concat([df_data_1_sampled, df_data_0])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.909438Z","iopub.execute_input":"2024-06-08T12:04:55.909866Z","iopub.status.idle":"2024-06-08T12:04:55.950389Z","shell.execute_reply.started":"2024-06-08T12:04:55.909835Z","shell.execute_reply":"2024-06-08T12:04:55.949683Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df_balanced['sentiment_rate'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.951322Z","iopub.execute_input":"2024-06-08T12:04:55.951592Z","iopub.status.idle":"2024-06-08T12:04:55.959236Z","shell.execute_reply.started":"2024-06-08T12:04:55.951568Z","shell.execute_reply":"2024-06-08T12:04:55.958311Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"sentiment_rate\n1    47787\n0    47787\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_balanced.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.960291Z","iopub.execute_input":"2024-06-08T12:04:55.960640Z","iopub.status.idle":"2024-06-08T12:04:55.973399Z","shell.execute_reply.started":"2024-06-08T12:04:55.960607Z","shell.execute_reply":"2024-06-08T12:04:55.972515Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"        uniqueID     drugName    condition  \\\n108930    157448  Guaifenesin        Cough   \n113550    164085    Ibuprofen  Period Pain   \n65273      94170   Trintellix   Depression   \n79763     115247     Diazepam      Anxiety   \n106256    153490  Doxycycline         Acne   \n\n                                                   review  rating       date  \\\n108930  \"Actually I was using Mucinex to control a nag...      10 2013-05-03   \n113550  \"I suffer with endometriosis. Due to this the ...       9 2014-08-17   \n65273   \"I&#039;ve been on this since last June, at 5 ...      10 2015-10-31   \n79763                    \"It helps keep things peaceful.\"      10 2009-05-18   \n106256  \"I&#039;m 20 years old now and I started this ...       7 2013-12-18   \n\n        usefulCount  sentiment_rate  \n108930           36               1  \n113550           16               1  \n65273            70               1  \n79763            20               1  \n106256            7               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniqueID</th>\n      <th>drugName</th>\n      <th>condition</th>\n      <th>review</th>\n      <th>rating</th>\n      <th>date</th>\n      <th>usefulCount</th>\n      <th>sentiment_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108930</th>\n      <td>157448</td>\n      <td>Guaifenesin</td>\n      <td>Cough</td>\n      <td>\"Actually I was using Mucinex to control a nag...</td>\n      <td>10</td>\n      <td>2013-05-03</td>\n      <td>36</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>113550</th>\n      <td>164085</td>\n      <td>Ibuprofen</td>\n      <td>Period Pain</td>\n      <td>\"I suffer with endometriosis. Due to this the ...</td>\n      <td>9</td>\n      <td>2014-08-17</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65273</th>\n      <td>94170</td>\n      <td>Trintellix</td>\n      <td>Depression</td>\n      <td>\"I&amp;#039;ve been on this since last June, at 5 ...</td>\n      <td>10</td>\n      <td>2015-10-31</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>79763</th>\n      <td>115247</td>\n      <td>Diazepam</td>\n      <td>Anxiety</td>\n      <td>\"It helps keep things peaceful.\"</td>\n      <td>10</td>\n      <td>2009-05-18</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106256</th>\n      <td>153490</td>\n      <td>Doxycycline</td>\n      <td>Acne</td>\n      <td>\"I&amp;#039;m 20 years old now and I started this ...</td>\n      <td>7</td>\n      <td>2013-12-18</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport keras\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nimport math\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.974588Z","iopub.execute_input":"2024-06-08T12:04:55.975443Z","iopub.status.idle":"2024-06-08T12:04:55.981352Z","shell.execute_reply.started":"2024-06-08T12:04:55.975415Z","shell.execute_reply":"2024-06-08T12:04:55.980627Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def review_clean(review): \n    # changing to lower case\n    lower = review.str.lower()\n    \n    # Replacing the repeating pattern of &#039;\n    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n    \n    # Removing all the special Characters\n    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n    \n    # Removing all the non ASCII characters\n    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n    \n    # Removing the leading and trailing Whitespaces\n    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n    \n    # Replacing multiple Spaces with Single Space\n    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n    \n    # Replacing Two or more dots with one\n    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n    \n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.982364Z","iopub.execute_input":"2024-06-08T12:04:55.982648Z","iopub.status.idle":"2024-06-08T12:04:55.993514Z","shell.execute_reply.started":"2024-06-08T12:04:55.982618Z","shell.execute_reply":"2024-06-08T12:04:55.992675Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Contraction Dictionary for the expansion\n\ncontractions_dict = {\n    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\",\n    \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n    \"doesn’t\": \"does not\", \"don't\": \"do not\", \"don’t\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\",\n    \"haven't\": \"have not\", \"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n    \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n    \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\"might've\": \"might have\",\n    \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n    \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n    \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n    \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y’all\": \"you all\", \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"ain’t\": \"am not\", \"aren’t\": \"are not\",\n    \"can’t\": \"cannot\", \"can’t’ve\": \"cannot have\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\", \"couldn’t’ve\": \"could not have\",\n    \"didn’t\": \"did not\", \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hadn’t’ve\": \"had not have\",\n    \"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he had\", \"he’d’ve\": \"he would have\", \"he’ll\": \"he will\", \"he’ll’ve\": \"he will have\",\n    \"he’s\": \"he is\", \"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\",\n    \"i’ll\": \"i will\", \"i’ll’ve\": \"i will have\", \"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\", \"it’d’ve\": \"it would have\",\n    \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\", \"it’s\": \"it is\", \"let’s\": \"let us\", \"ma’am\": \"madam\", \"mayn’t\": \"may not\",\n    \"might’ve\": \"might have\", \"mightn’t\": \"might not\", \"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\",\n    \"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\", \"o’clock\": \"of the clock\",\n    \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\", \"shan’t\": \"shall not\", \"sha’n’t\": \"shall not\", \"shan’t’ve\": \"shall not have\",\n    \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\", \"she’ll’ve\": \"she will have\", \"she’s\": \"she is\",\n    \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\", \"so’ve\": \"so have\", \"so’s\": \"so is\",\n    \"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\", \"there’d’ve\": \"there would have\",\n    \"there’s\": \"there is\", \"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\", \"they’ll’ve\": \"they will have\",\n    \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\", \"we’d’ve\": \"we would have\",\n    \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\",\n    \"what’ll’ve\": \"what will have\", \"what’re\": \"what are\", \"what’s\": \"what is\", \"what’ve\": \"what have\", \"when’s\": \"when is\",\n    \"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\",\n    \"who’ll’ve\": \"who will have\", \"who’s\": \"who is\", \"who’ve\": \"who have\",\"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\",\n    \"won’t\": \"will not\", \"won’t’ve\": \"will not have\", \"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\",\n    \"y’all\": \"you all\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\", \"y’all’d’ve\": \"you all would have\", \"y’all’re\": \"you all are\",\n    \"y’all’ve\": \"you all have\", \"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\",\n    \"you’re\": \"you are\", \"you’re\": \"you are\", \"you’ve\": \"you have\"\n}\ncontractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n\n# Function expand the contractions if there's any\ndef expand_contractions(s, contractions_dict=contractions_dict):\n    def replace(match):\n        return contractions_dict[match.group(0)]\n    return contractions_re.sub(replace, s)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:04:55.996723Z","iopub.execute_input":"2024-06-08T12:04:55.997056Z","iopub.status.idle":"2024-06-08T12:04:56.022014Z","shell.execute_reply.started":"2024-06-08T12:04:55.997031Z","shell.execute_reply":"2024-06-08T12:04:56.021202Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#df_data['review_clean'] = df_data['review'].apply(review_clean)\ndf_data['review_clean'] = review_clean(df_data['review'])\n\n# Expanding the contractions\ndf_data['review_clean'] = df_data['review_clean'].apply(lambda x: expand_contractions(x))\n\n# Removing punctuations\ndf_data['review_clean'] = df_data['review_clean'].apply(lambda x: ''.join(word for word in x if word not in punctuation))","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:05:00.060163Z","iopub.execute_input":"2024-06-08T12:05:00.060571Z","iopub.status.idle":"2024-06-08T12:05:39.302067Z","shell.execute_reply.started":"2024-06-08T12:05:00.060536Z","shell.execute_reply":"2024-06-08T12:05:39.301269Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_balanced.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:05:39.303610Z","iopub.execute_input":"2024-06-08T12:05:39.303914Z","iopub.status.idle":"2024-06-08T12:05:39.317183Z","shell.execute_reply.started":"2024-06-08T12:05:39.303886Z","shell.execute_reply":"2024-06-08T12:05:39.316086Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"        uniqueID     drugName    condition  \\\n108930    157448  Guaifenesin        Cough   \n113550    164085    Ibuprofen  Period Pain   \n65273      94170   Trintellix   Depression   \n79763     115247     Diazepam      Anxiety   \n106256    153490  Doxycycline         Acne   \n\n                                                   review  rating       date  \\\n108930  \"Actually I was using Mucinex to control a nag...      10 2013-05-03   \n113550  \"I suffer with endometriosis. Due to this the ...       9 2014-08-17   \n65273   \"I&#039;ve been on this since last June, at 5 ...      10 2015-10-31   \n79763                    \"It helps keep things peaceful.\"      10 2009-05-18   \n106256  \"I&#039;m 20 years old now and I started this ...       7 2013-12-18   \n\n        usefulCount  sentiment_rate  \n108930           36               1  \n113550           16               1  \n65273            70               1  \n79763            20               1  \n106256            7               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniqueID</th>\n      <th>drugName</th>\n      <th>condition</th>\n      <th>review</th>\n      <th>rating</th>\n      <th>date</th>\n      <th>usefulCount</th>\n      <th>sentiment_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108930</th>\n      <td>157448</td>\n      <td>Guaifenesin</td>\n      <td>Cough</td>\n      <td>\"Actually I was using Mucinex to control a nag...</td>\n      <td>10</td>\n      <td>2013-05-03</td>\n      <td>36</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>113550</th>\n      <td>164085</td>\n      <td>Ibuprofen</td>\n      <td>Period Pain</td>\n      <td>\"I suffer with endometriosis. Due to this the ...</td>\n      <td>9</td>\n      <td>2014-08-17</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65273</th>\n      <td>94170</td>\n      <td>Trintellix</td>\n      <td>Depression</td>\n      <td>\"I&amp;#039;ve been on this since last June, at 5 ...</td>\n      <td>10</td>\n      <td>2015-10-31</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>79763</th>\n      <td>115247</td>\n      <td>Diazepam</td>\n      <td>Anxiety</td>\n      <td>\"It helps keep things peaceful.\"</td>\n      <td>10</td>\n      <td>2009-05-18</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106256</th>\n      <td>153490</td>\n      <td>Doxycycline</td>\n      <td>Acne</td>\n      <td>\"I&amp;#039;m 20 years old now and I started this ...</td>\n      <td>7</td>\n      <td>2013-12-18</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport warnings; warnings.simplefilter('ignore')\nimport nltk\nimport re\nimport string\nfrom string import punctuation\nfrom nltk import ngrams\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:08:18.171319Z","iopub.execute_input":"2024-06-08T12:08:18.172097Z","iopub.status.idle":"2024-06-08T12:08:18.178949Z","shell.execute_reply.started":"2024-06-08T12:08:18.172062Z","shell.execute_reply":"2024-06-08T12:08:18.177198Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Removing the stopwords\nstop_words = set(stopwords.words('english'))\npunctuation = punctuation + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\ndf_data['review_clean'] = df_data['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:09:45.312415Z","iopub.execute_input":"2024-06-08T12:09:45.313307Z","iopub.status.idle":"2024-06-08T12:09:48.138507Z","shell.execute_reply.started":"2024-06-08T12:09:45.313274Z","shell.execute_reply":"2024-06-08T12:09:48.137694Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Removing the word stems using the Snowball Stemmer\nSnow_ball = SnowballStemmer(\"english\")\ndf_data['review_clean'] = df_data['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:10:12.377899Z","iopub.execute_input":"2024-06-08T12:10:12.378584Z","iopub.status.idle":"2024-06-08T12:12:22.871899Z","shell.execute_reply.started":"2024-06-08T12:10:12.378541Z","shell.execute_reply":"2024-06-08T12:12:22.871074Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df_data['review_clean'].head(20)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:12:22.873519Z","iopub.execute_input":"2024-06-08T12:12:22.873805Z","iopub.status.idle":"2024-06-08T12:12:22.880932Z","shell.execute_reply.started":"2024-06-08T12:12:22.873780Z","shell.execute_reply":"2024-06-08T12:12:22.880038Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0     im 21 year old recent found might pcos havent ...\n1     shot 11 year month ago never 1 period even spo...\n2     ive four shot point birth control pill year du...\n3     total 3 shot got first one leav hospit give bi...\n4     im 18 got heavi bleed ive alway heard bc make ...\n5     im 19 heavi pain period sinc forev got depo sh...\n6     im 30 year old woman got shot august 9th bleed...\n7     im 17 year old got shot august 2015 person don...\n8     first month awesom absolut wonder start light ...\n9     start depo shot year ago origin bled 3 week da...\n10    im 17 went depo heavi bleed like heavi would g...\n11    1st shot sept 2nd nonstop bleed sinc side effe...\n12    got shot 6 week post partum nurs seen high rec...\n13    one inject june 2012 see gp want tri babi soon...\n14    depo provera age 1518 pros pregnant period con...\n15    got shot 2 half month ago stop bleed spot firs...\n16    got depo shot later part septemb octob didnt p...\n17    hyperplasia last year well endometriosi surger...\n18    im current depo shot babi august start shot mi...\n19    never ever ever ever get back caus horribl dep...\nName: review_clean, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Separating the day, month and year from the Date\n\ndf_data['day'] = df_data['date'].dt.day\ndf_data['month'] = df_data['date'].dt.month\ndf_data['year'] = df_data['date'].dt.year","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:12:22.882049Z","iopub.execute_input":"2024-06-08T12:12:22.882390Z","iopub.status.idle":"2024-06-08T12:12:22.910795Z","shell.execute_reply.started":"2024-06-08T12:12:22.882358Z","shell.execute_reply":"2024-06-08T12:12:22.909958Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def sentiment(review):\n    # Sentiment polarity of the reviews\n    pol = []\n    for i in review:\n        analysis = TextBlob(i)\n        pol.append(analysis.sentiment.polarity)\n    return pol","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:12:22.912412Z","iopub.execute_input":"2024-06-08T12:12:22.912696Z","iopub.status.idle":"2024-06-08T12:12:22.917038Z","shell.execute_reply.started":"2024-06-08T12:12:22.912673Z","shell.execute_reply":"2024-06-08T12:12:22.916162Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df_data['sentiment'] = sentiment(df_data['review'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:12:22.918092Z","iopub.execute_input":"2024-06-08T12:12:22.918511Z","iopub.status.idle":"2024-06-08T12:14:32.829776Z","shell.execute_reply.started":"2024-06-08T12:12:22.918456Z","shell.execute_reply":"2024-06-08T12:14:32.828941Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df_data['sentiment_clean'] = sentiment(df_data['review_clean'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:14:32.831933Z","iopub.execute_input":"2024-06-08T12:14:32.832291Z","iopub.status.idle":"2024-06-08T12:15:43.803631Z","shell.execute_reply.started":"2024-06-08T12:14:32.832258Z","shell.execute_reply":"2024-06-08T12:15:43.802820Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"np.corrcoef(df_data['sentiment'], df_data['rating'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:15:43.804739Z","iopub.execute_input":"2024-06-08T12:15:43.805024Z","iopub.status.idle":"2024-06-08T12:15:43.814161Z","shell.execute_reply.started":"2024-06-08T12:15:43.804998Z","shell.execute_reply":"2024-06-08T12:15:43.813256Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array([[1.        , 0.34870057],\n       [0.34870057, 1.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"np.corrcoef(df_data['sentiment_clean'], df_data['rating'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:15:43.815290Z","iopub.execute_input":"2024-06-08T12:15:43.815763Z","iopub.status.idle":"2024-06-08T12:15:43.824047Z","shell.execute_reply.started":"2024-06-08T12:15:43.815727Z","shell.execute_reply":"2024-06-08T12:15:43.823242Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"array([[1.        , 0.23278758],\n       [0.23278758, 1.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning the reviews without removing the stop words and using snowball stemmer\n\ndf_data['review_clean_ss'] = review_clean(df_data['review'])\n\ndf_data['review_clean_ss'] = df_data['review_clean_ss'].apply(lambda x: expand_contractions(x))\n\ndf_data['review_clean_ss'] = df_data['review_clean_ss'].apply(lambda x: ''.join(word for word in x if word not in punctuation))\n\ndf_data['sentiment_clean_ss'] = sentiment(df_data['review_clean_ss'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:15:51.116922Z","iopub.execute_input":"2024-06-08T12:15:51.117281Z","iopub.status.idle":"2024-06-08T12:18:23.369658Z","shell.execute_reply.started":"2024-06-08T12:15:51.117250Z","shell.execute_reply":"2024-06-08T12:18:23.368663Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"np.corrcoef(df_data['sentiment_clean_ss'], df_data['rating'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:18:23.371327Z","iopub.execute_input":"2024-06-08T12:18:23.371628Z","iopub.status.idle":"2024-06-08T12:18:23.380284Z","shell.execute_reply.started":"2024-06-08T12:18:23.371603Z","shell.execute_reply":"2024-06-08T12:18:23.379376Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"array([[1.        , 0.34540542],\n       [0.34540542, 1.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"# Label Encoding Drugname and Conditions\nlabel_encoder_feat = {}\nfor feature in ['drugName', 'condition']:\n    label_encoder_feat[feature] = LabelEncoder()\n    df_data[feature] = label_encoder_feat[feature].fit_transform(df_data[feature])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:18:23.383164Z","iopub.execute_input":"2024-06-08T12:18:23.383414Z","iopub.status.idle":"2024-06-08T12:18:23.476770Z","shell.execute_reply.started":"2024-06-08T12:18:23.383391Z","shell.execute_reply":"2024-06-08T12:18:23.476010Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"#### **Using GloVe**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef load_glove_embeddings(path):\n    embeddings_index = {}\n    with open(path, 'r', encoding='utf-8') as file:\n        for line in file:\n            values = line.split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = vector\n    return embeddings_index\n\nglove_path = '/kaggle/input/glove6b100dtxt/glove.6B.100d.txt'\nembeddings_index = load_glove_embeddings(glove_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:18:23.478559Z","iopub.execute_input":"2024-06-08T12:18:23.478838Z","iopub.status.idle":"2024-06-08T12:18:38.921078Z","shell.execute_reply.started":"2024-06-08T12:18:23.478813Z","shell.execute_reply":"2024-06-08T12:18:38.920236Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"texts = df_train['review'].tolist()  # Convert DataFrame column to list\nlabels = df_train['sentiment_rate'].values  # Get labels as an array","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:18:38.922077Z","iopub.execute_input":"2024-06-08T12:18:38.922340Z","iopub.status.idle":"2024-06-08T12:18:38.933347Z","shell.execute_reply.started":"2024-06-08T12:18:38.922316Z","shell.execute_reply":"2024-06-08T12:18:38.932375Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"#### **Tokenize Data**","metadata":{}},{"cell_type":"code","source":"# Assuming 'texts' is a list of strings from your dataset\ntokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=100)\n\n# Assuming you have a binary label for each text\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:18:38.934672Z","iopub.execute_input":"2024-06-08T12:18:38.935057Z","iopub.status.idle":"2024-06-08T12:19:02.075255Z","shell.execute_reply.started":"2024-06-08T12:18:38.935021Z","shell.execute_reply":"2024-06-08T12:19:02.074145Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Found 51382 unique tokens.\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_dim = 100\nmaxlen = 100  # Same as 'maxlen' in pad_sequences\n\n# Preparing the GloVe embedding matrix\nembedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:19:02.076644Z","iopub.execute_input":"2024-06-08T12:19:02.077033Z","iopub.status.idle":"2024-06-08T12:19:02.189823Z","shell.execute_reply.started":"2024-06-08T12:19:02.076996Z","shell.execute_reply":"2024-06-08T12:19:02.188650Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"#### **Prepare the Model**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:19:02.191249Z","iopub.execute_input":"2024-06-08T12:19:02.191668Z","iopub.status.idle":"2024-06-08T12:19:02.198984Z","shell.execute_reply.started":"2024-06-08T12:19:02.191630Z","shell.execute_reply":"2024-06-08T12:19:02.197965Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                    embedding_dim,\n                    weights=[embedding_matrix],\n                    input_length=maxlen,\n                    trainable=False))\nmodel.add(LSTM(128))\nmodel.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:19:15.706327Z","iopub.execute_input":"2024-06-08T12:19:15.706698Z","iopub.status.idle":"2024-06-08T12:19:16.567548Z","shell.execute_reply.started":"2024-06-08T12:19:15.706667Z","shell.execute_reply":"2024-06-08T12:19:16.566774Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:19:16.903002Z","iopub.execute_input":"2024-06-08T12:19:16.903658Z","iopub.status.idle":"2024-06-08T12:19:16.923118Z","shell.execute_reply.started":"2024-06-08T12:19:16.903626Z","shell.execute_reply":"2024-06-08T12:19:16.922433Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"#### **Training Process**","metadata":{}},{"cell_type":"code","source":"history = model.fit(data_train, labels_train, epochs=20, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:49:48.608328Z","iopub.execute_input":"2024-06-08T12:49:48.608699Z","iopub.status.idle":"2024-06-08T12:56:46.918665Z","shell.execute_reply.started":"2024-06-08T12:49:48.608668Z","shell.execute_reply":"2024-06-08T12:56:46.917900Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.7512 - loss: 0.5109 - val_accuracy: 0.8151 - val_loss: 0.3987\nEpoch 2/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8354 - loss: 0.3677 - val_accuracy: 0.8526 - val_loss: 0.3349\nEpoch 3/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8604 - loss: 0.3165 - val_accuracy: 0.8623 - val_loss: 0.3168\nEpoch 4/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.2788 - val_accuracy: 0.8669 - val_loss: 0.3068\nEpoch 5/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.2465 - val_accuracy: 0.8739 - val_loss: 0.3033\nEpoch 6/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.2107 - val_accuracy: 0.8807 - val_loss: 0.3037\nEpoch 7/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9319 - loss: 0.1727 - val_accuracy: 0.8801 - val_loss: 0.3078\nEpoch 8/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.1432 - val_accuracy: 0.8856 - val_loss: 0.3151\nEpoch 9/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.1118 - val_accuracy: 0.8902 - val_loss: 0.3463\nEpoch 10/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9670 - loss: 0.0926 - val_accuracy: 0.8898 - val_loss: 0.3632\nEpoch 11/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0751 - val_accuracy: 0.8917 - val_loss: 0.3809\nEpoch 12/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0653 - val_accuracy: 0.8891 - val_loss: 0.4093\nEpoch 13/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0538 - val_accuracy: 0.8944 - val_loss: 0.4462\nEpoch 14/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0477 - val_accuracy: 0.8909 - val_loss: 0.4600\nEpoch 15/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0460 - val_accuracy: 0.8906 - val_loss: 0.4530\nEpoch 16/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0457 - val_accuracy: 0.8964 - val_loss: 0.4996\nEpoch 17/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0353 - val_accuracy: 0.8951 - val_loss: 0.5209\nEpoch 18/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0361 - val_accuracy: 0.8916 - val_loss: 0.5638\nEpoch 19/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0347 - val_accuracy: 0.8932 - val_loss: 0.5154\nEpoch 20/20\n\u001b[1m3208/3208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0341 - val_accuracy: 0.8939 - val_loss: 0.5489\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions_prob = model.predict(data_test)\npredictions = (predictions_prob > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:56:46.921854Z","iopub.execute_input":"2024-06-08T12:56:46.922135Z","iopub.status.idle":"2024-06-08T12:56:50.129928Z","shell.execute_reply.started":"2024-06-08T12:56:46.922103Z","shell.execute_reply":"2024-06-08T12:56:50.128692Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Classification Report**","metadata":{}},{"cell_type":"code","source":"report = classification_report(labels_test, predictions, target_names=['Negative', 'Positive'])\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:56:50.131400Z","iopub.execute_input":"2024-06-08T12:56:50.131769Z","iopub.status.idle":"2024-06-08T12:56:50.157097Z","shell.execute_reply.started":"2024-06-08T12:56:50.131734Z","shell.execute_reply":"2024-06-08T12:56:50.156151Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    Negative       0.81      0.82      0.81      9519\n    Positive       0.92      0.92      0.92     22561\n\n    accuracy                           0.89     32080\n   macro avg       0.87      0.87      0.87     32080\nweighted avg       0.89      0.89      0.89     32080\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Accuracy**","metadata":{}},{"cell_type":"code","source":"final_train_accuracy = history.history['accuracy'][-1]  # Last epoch training accuracy\nfinal_val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n\nprint(f'Final Training Accuracy: {final_train_accuracy:.2f}')\nprint(f'Final Validation Accuracy: {final_val_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:58:50.411294Z","iopub.execute_input":"2024-06-08T12:58:50.411932Z","iopub.status.idle":"2024-06-08T12:58:50.417407Z","shell.execute_reply.started":"2024-06-08T12:58:50.411898Z","shell.execute_reply":"2024-06-08T12:58:50.416398Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Final Training Accuracy: 0.99\nFinal Validation Accuracy: 0.89\n","output_type":"stream"}]},{"cell_type":"code","source":"test_accuracy = accuracy_score(labels_test, predictions)\nprint(f'Test Accuracy: {test_accuracy:.5f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-08T12:59:07.736100Z","iopub.execute_input":"2024-06-08T12:59:07.736441Z","iopub.status.idle":"2024-06-08T12:59:07.743252Z","shell.execute_reply.started":"2024-06-08T12:59:07.736412Z","shell.execute_reply":"2024-06-08T12:59:07.742355Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.88900\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Drugs Recommendation**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nimport pandas as pd\n\n# Contoh penggunaan TfidfVectorizer yang menghasilkan sparse matrix\ndata = {'condition': ['Diabetes', 'Diabetes', 'Heart Attack', 'Cold', 'Flu'],\n        'description': ['High sugar levels.', 'Insulin resistance.', 'Heart pain and discomfort.', 'Running nose and sneezing.', 'High fever and chills.']}\n\ndf = pd.DataFrame(data)\n\n# Menggunakan TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(df['description'])\n\n# Hitung cosine similarity\ncosine_sim = linear_kernel(X, X)\n\n# Implementasi function rekomendasi\ndef recommend_condition(index, cosine_sim, top_n=2):\n    sim_scores = list(enumerate(cosine_sim[index]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    top_indices = [i[0] for i in sim_scores[1: top_n+1]]  # skip the self similarity\n    return df['condition'].iloc[top_indices]\n\n# Contoh pemanggilan fungsi\nrecommend_condition(0, cosine_sim)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:33:20.412443Z","iopub.execute_input":"2024-06-08T20:33:20.412960Z","iopub.status.idle":"2024-06-08T20:33:20.435473Z","shell.execute_reply.started":"2024-06-08T20:33:20.412926Z","shell.execute_reply":"2024-06-08T20:33:20.434435Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"4         Flu\n1    Diabetes\nName: condition, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}