{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of Drug Recommendation System based on the Condition of the Patient using Bidirectional Encoder Representations from Transformers.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":171475,"sourceType":"datasetVersion","datasetId":76158}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Packages","metadata":{"id":"dw3JCclyAlDI"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:07:54.995422Z","iopub.execute_input":"2024-06-09T13:07:54.995889Z","iopub.status.idle":"2024-06-09T13:07:56.657492Z","shell.execute_reply.started":"2024-06-09T13:07:54.995854Z","shell.execute_reply":"2024-06-09T13:07:56.655825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings \n\nimport os\nimport wget\nimport time\nimport datetime\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef, accuracy_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"YYWHU49hAoAe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download Dataset","metadata":{"id":"oiUVj6Hb42nA"}},{"cell_type":"code","source":"# Importing the datasets\n\ndf_train = pd.read_csv(\"/kaggle/input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv\")\nprint (\"The shape of the train set given is : \", df_train.shape)\n\ndf_train.head()","metadata":{"id":"OYsXU7Ix5BlN","outputId":"bbb4a3f0-8616-49e6-81a1-644e27ec75c5","execution":{"iopub.status.busy":"2024-06-09T13:08:23.241414Z","iopub.execute_input":"2024-06-09T13:08:23.242087Z","iopub.status.idle":"2024-06-09T13:08:25.477822Z","shell.execute_reply.started":"2024-06-09T13:08:23.242046Z","shell.execute_reply":"2024-06-09T13:08:25.476312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dropna(subset=['condition'], inplace=True)","metadata":{"id":"5mPvmdcu5i2r","outputId":"309026ec-8f22-495e-919c-520eaf304093","execution":{"iopub.status.busy":"2024-06-09T13:08:39.410028Z","iopub.execute_input":"2024-06-09T13:08:39.410433Z","iopub.status.idle":"2024-06-09T13:08:39.470629Z","shell.execute_reply.started":"2024-06-09T13:08:39.410381Z","shell.execute_reply":"2024-06-09T13:08:39.468978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['uniqueID', 'date'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:09:28.081726Z","iopub.execute_input":"2024-06-09T13:09:28.082252Z","iopub.status.idle":"2024-06-09T13:09:28.107172Z","shell.execute_reply.started":"2024-06-09T13:09:28.082212Z","shell.execute_reply":"2024-06-09T13:09:28.105528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:09:50.801870Z","iopub.execute_input":"2024-06-09T13:09:50.802452Z","iopub.status.idle":"2024-06-09T13:09:52.316309Z","shell.execute_reply.started":"2024-06-09T13:09:50.802412Z","shell.execute_reply":"2024-06-09T13:09:52.314795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_review(review):\n    # Convert to lowercase\n    review = review.lower()\n    \n    # Remove punctuation\n    review = review.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenize the review\n    tokens = nltk.word_tokenize(review)\n    \n    # Remove stop words\n    tokens = [word for word in tokens if word not in stopwords.words('english')]\n    \n    # Join the cleaned tokens back together\n    cleaned_review = ' '.join(tokens)\n    \n    return cleaned_review","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:10:04.366570Z","iopub.execute_input":"2024-06-09T13:10:04.367001Z","iopub.status.idle":"2024-06-09T13:10:04.376628Z","shell.execute_reply.started":"2024-06-09T13:10:04.366968Z","shell.execute_reply":"2024-06-09T13:10:04.374839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:10:31.471506Z","iopub.execute_input":"2024-06-09T13:10:31.471916Z","iopub.status.idle":"2024-06-09T13:10:33.261254Z","shell.execute_reply.started":"2024-06-09T13:10:31.471884Z","shell.execute_reply":"2024-06-09T13:10:33.259576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['review'] = df_train['review'].apply(lambda x: clean_review(x))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:11:10.199731Z","iopub.execute_input":"2024-06-09T13:11:10.200206Z","iopub.status.idle":"2024-06-09T13:11:11.800681Z","shell.execute_reply.started":"2024-06-09T13:11:10.200169Z","shell.execute_reply":"2024-06-09T13:11:11.799022Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Retrieving Features Dataset\")\n\nsentences = df.review.values\nlabels = df['rating']\ndrug_name = df.drugName.values\ncondition = df.condition.values","metadata":{"id":"n8Y6nTeW8Fib","outputId":"8708f39b-baf6-4aa6-fbfe-e8a502dba7a7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding","metadata":{"id":"_F3aZPqdePo3"}},{"cell_type":"code","source":"labels = labels.apply(lambda x: 1 if x >= 5.0 else 0)\nlabels = np.asarray(labels)\n\nprint(\"Encoding Labels\")","metadata":{"id":"RAO0E0UDSbQx","outputId":"1fdb2e0a-8a61-4a04-c84a-5ba58271acdb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bert Tokenizer","metadata":{"id":"YsCb1LzP94ik"}},{"cell_type":"code","source":"print('Downloading BERT tokenizer...')\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"id":"bYWmhDFx8j9Z","outputId":"2fc07c6f-9fdb-4740-9a30-57f057fa2f00"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization","metadata":{"id":"L0XzvtDS_Sq3"}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\ninput_ids = []\nattention_mask = []\n\nfor s in sentences:\n\n    input_encoded = tokenizer.encode_plus(\n                        s,                      \n                        add_special_tokens = True, \n                        max_length = 64,           \n                        truncation = True,\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   \n                        return_tensors = 'pt',    \n                   )\n      \n    input_ids.append(input_encoded['input_ids'])\n  \n    attention_mask.append(input_encoded['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_mask = torch.cat(attention_mask, dim=0)\nlabels = torch.tensor(labels)\n\nprint('Tokenization Done')","metadata":{"id":"Qk1y0Gc-OoK_","outputId":"74f55d64-0c69-4f2d-cbc2-0afc89fc6027"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Split","metadata":{"id":"jqN2kjflBZ8a"}},{"cell_type":"code","source":"dfs = TensorDataset(input_ids, attention_mask, labels)\n\nsize_train = int(0.9 * len(dfs))\nsize_val = len(dfs) - size_train\n\ntrain_data, val_data = random_split(dfs, [size_train, size_val])\n\nprint(\"{:,} is the training dataset size\".format(size_train))\nprint(\"{:,} is the validation dataset size\".format(size_val))","metadata":{"id":"NJUosWUgRRr_","outputId":"2ea31627-639c-44c2-c3c6-cfbc6927b766"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Batch Sampling","metadata":{"id":"W5FVOe2TD2s3"}},{"cell_type":"code","source":"bs = 100\n\ntrain_dl = DataLoader(\n            train_data,\n            sampler = RandomSampler(train_data),\n            batch_size = bs\n)\n\nvalid_dl = DataLoader(\n            val_data,\n            sampler = SequentialSampler(val_data),\n            batch_size = bs\n)\n\nprint(\"Batch Sampling Done\")","metadata":{"id":"Ziccrq0fC4hx","outputId":"16eabf6e-1b86-453c-e2b5-b1916e0c4d27"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BERT Model","metadata":{"id":"rxSDk9-1Eq_H"}},{"cell_type":"code","source":"dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmod = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels = 2,\n    output_attentions = False,\n    output_hidden_states = False\n)\n\nmod.to(dev)","metadata":{"id":"v_zG29mpEeAt","outputId":"87b86e15-70a2-406e-8b17-158746394aee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimizer","metadata":{"id":"3ljkwzYsJ_KK"}},{"cell_type":"code","source":"opt = AdamW(\n    mod.parameters(),\n    lr = 3e-5,\n    eps = 1e-8\n)\n\nprint(\"Optimizer Initialized\")","metadata":{"id":"D87kPyq1HsjD","outputId":"c77867d3-aa1f-4cdb-a15e-833dd303c1e2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scheduler","metadata":{"id":"QcIoyUsaKeJX"}},{"cell_type":"code","source":"epoch = 3\nts = len(train_dl) * epoch\n\nsch = get_linear_schedule_with_warmup(\n    opt,\n    num_warmup_steps = 0,\n    num_training_steps = ts\n)\n\nprint(\"Scheduler Initialized\")","metadata":{"id":"3BEocJciKWL7","outputId":"31dcea3a-97ee-4eca-cb97-b34e229406dc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy","metadata":{"id":"3Krbbq9XLiVw"}},{"cell_type":"code","source":"def acc(preds, labels):\n    preds_flat = np.argmax(preds, axis = -1).flatten()\n    labels_flat = labels\n\n    return np.sum(preds_flat == labels_flat)/len(preds_flat)\n\nprint(\"Accuracy Function Defined\")","metadata":{"id":"7LNJB1Z2Led3","outputId":"882256cc-ff7a-46c6-bb57-c0eff98621c1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Time","metadata":{"id":"EJXQvsFeNXYC"}},{"cell_type":"code","source":"def t(s):\n    p = int(round(s))\n    return str(datetime.timedelta(seconds = p))\n\nprint(\"Time Function Defined\")","metadata":{"id":"v_EyfnX1NAxf","outputId":"749bfcac-1017-4ef7-a328-c9692a41c13a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Validation","metadata":{"id":"TmlMxL40WZE1"}},{"cell_type":"code","source":"seed = 42\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nstats = []\n\ntot_t0 = time.time()\n\nfor i in range(0, epoch):\n\n    print(\"\\n\")\n    print(\"Training epoch {} / {}\".format(i + 1, epoch))\n    print(\"Training.......................\")\n    print(\"\\n\")\n\n    t0 = time.time()\n\n    tot_train_loss = 0\n\n    mod.train()\n\n    for s, b in enumerate(train_dl):\n\n        if s % bs == 0 and not s == 0:\n\n            timef = t(time.time() - t0)\n\n            print(\"Batch {} of {} has elasped in {}\".format(s, len(train_dl), timef))\n\n        input_ids_d = b[0].to(dev)\n        attention_mask_d = b[1].to(dev)\n        labels_d = b[2].to(dev)\n\n        mod.zero_grad()\n\n        cost, logits = mod(\n              input_ids = input_ids_d,\n              attention_mask = attention_mask_d,\n              labels = labels_d,\n              token_type_ids = None,\n              return_dict = False\n        )\n\n        tot_train_loss += cost.item()\n\n        cost.backward()\n\n        torch.nn.utils.clip_grad_norm_(mod.parameters(), 1.0)\n\n        opt.step()\n\n        sch.step()\n\n    avg_tloss = tot_train_loss / len(train_dl)\n\n    train_time = t(time.time() - t0)\n\n    print(\"\\n\")\n    print(\"Average Training Loss is {}\".format(avg_tloss))\n    print(\"Training Time per epoch is {}\".format(train_time))\n\n    print(\"\\n\")\n    print(\"Validating.......................\")\n\n    t0 = time.time()\n\n    mod.eval()\n\n    tot_eval_loss = 0\n    tot_eval_steps = 0\n\n    for s, b in enumerate(valid_dl):\n\n        input_ids_d = b[0].to(dev)\n        attention_mask_d = b[1].to(dev)\n        labels_d = b[2].to(dev)\n\n        mod.zero_grad()\n\n        with torch.no_grad():\n\n            cost, logits = mod(\n                               input_ids = input_ids_d,\n                               attention_mask = attention_mask_d,\n                               labels = labels_d,\n                               token_type_ids = None,\n                               return_dict = False\n                               )\n\n        tot_eval_loss += cost.item()\n\n        logits = logits.detach().cpu().numpy()\n        labelx = labels_d.detach().cpu().numpy()\n\n    avg_vloss = tot_eval_loss / len(valid_dl)\n    valid_time = t(time.time() - t0)\n\n    print(\"\\n\")\n    print(\"Average Validation Loss is {}\".format(avg_vloss))\n    print(\"Validation Time per epoch is {}\".format(valid_time))\n\n    stats.append({\n        'epoch' : i + 1,\n        'Training Loss' : avg_tloss,\n        'Training Time' : train_time,\n        'Validation Loss' : avg_vloss,\n        'Validation Time' : valid_time\n    })\n\nprint(\"\\n\")\nprint(\"Completed!!!\")\nprint(\"Total Time Taken for Training and Validation is {:}\".format(t(time.time() - tot_t0)))","metadata":{"id":"0kWZoqQCsYpO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model Weights","metadata":{"id":"Dtpp0iBUG-Tb"}},{"cell_type":"code","source":"torch.save(mod.state_dict(), \"/content/drive/MyDrive/BERT Models/BERT_Weights.pt\")\nprint(\"Model Saved\")","metadata":{"id":"5DkBMHnFLI54","outputId":"5dd01338-bfa9-4ec5-ac6d-240c1a5a5c79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Statistics","metadata":{"id":"SLjAZ7J-Zukd"}},{"cell_type":"code","source":"statistics = pd.DataFrame(data = stats)\nstatistics = statistics.set_index('epoch')\n\nstatistics","metadata":{"id":"VFecsb-6MQzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Data","metadata":{"id":"hjTsBAI3crHy"}},{"cell_type":"code","source":"df_test = pd.read_csv(\"./drugsComTest_raw.tsv\", delimiter = \"\\t\", header = 0, names = [None, \"drugName\", \"condition\", \"review\", \"rating\", \"date\", \"usefulCount\"])\ndf_test","metadata":{"id":"AvVVEXOG0r1C","outputId":"5d6bc4cd-f940-4983-9d5b-3552b150b7c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\nprint(\"Retrieving Features Dataset\\n\")\nsentences = df_test.review.values\nlabels = df_test['rating']\ndrug_name = df_test.drugName.values\ncondition = df_test.condition.values\n\nlabels = labels.apply(lambda x: 1 if x >= 5.0 else 0)\nlabels = np.asarray(labels)\n\nprint(\"Encoding Labels\\n\")\n\ninput_ids = []\nattention_mask = []\n\nfor s in sentences:\n  \n    input_encoded = tokenizer.encode_plus(\n                        s,                     \n                        add_special_tokens = True, \n                        max_length = 64, \n                        truncation = True,        \n                        pad_to_max_length = True,\n                        return_attention_mask = True,  \n                        return_tensors = 'pt',     \n                   )\n       \n    input_ids.append(input_encoded['input_ids'])\n    attention_mask.append(input_encoded['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim = 0)\nattention_mask = torch.cat(attention_mask, dim = 0)\nlabels = torch.tensor(labels)\n  \nbs = 100\n\npred_data = TensorDataset(input_ids, attention_mask, labels)\npred_sampler = SequentialSampler(pred_data)\npred_dl = DataLoader(pred_data, sampler = pred_sampler, batch_size = bs)\n\nprint('Test Data prepared')\n","metadata":{"id":"shDEVBRKbPr2","outputId":"483d2d09-c838-4ffa-8b82-3f693f42c380"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{"id":"SB_vZQ7EfmCl"}},{"cell_type":"code","source":"test_acc = 0\n\nmod.eval()\n\npreds, tl = [], []\nfor s, b in enumerate(pred_dl):\n\n    b = tuple(t.to(dev) for t in b)\n\n    input_idsx, attention_maskx, labelsx = b\n\n    with torch.no_grad():\n\n        outs = mod(\n            input_ids = input_idsx, \n            attention_mask = attention_maskx, \n            token_type_ids = None, \n            )\n    \n        logits = outs[0]\n\n        logits = logits.detach().cpu().numpy()\n        labels = labelsx.to('cpu').numpy()\n\n        ta = acc(logits, labels)\n        test_acc =  test_acc + ta\n\n        preds.append(logits)\n        tl.append(labels)\n\ntest_acc = (test_acc / len(pred_dl)) * 100\n\nprint('Prediction Done!')\nprint('Test Accuracy is {}%'.format(test_acc))","metadata":{"id":"MgCcuaHodk_q","outputId":"2fc91da3-75e9-478d-9c4d-ebc14b1dd334"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance Visualization","metadata":{"id":"tPRPQ_odMe6h"}},{"cell_type":"markdown","source":"### Matthew's Correlation Coefficient","metadata":{"id":"PMO7RphziG-a"}},{"cell_type":"code","source":"mat = []\n\nfor i in range(len(tl)):\n\n    pred_lab = np.argmax(preds[i], axis = 1).flatten()\n\n    mat_set = matthews_corrcoef(tl[i], pred_lab)\n    mat.append(mat_set)\n\nprint(\"Matthews's Correlation Coefficients Obtained\")","metadata":{"id":"IogIm7yShjta","outputId":"1aac92fe-9f16-4a9f-ae21-209a5d664dfd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MCC Graph","metadata":{"id":"ts2p1mIti7Qi"}},{"cell_type":"code","source":"mat_50  = mat[:50] \n\nfig = sns.barplot(x = list(range(len(mat_50))), y = mat_50)\n\nplt.title('MCC Graph')\nplt.xlabel('#Batch')\nplt.ylabel('MCC Score')\nplt.xticks(rotation=90)\n\nplt.show()","metadata":{"id":"9oTJ7cMFi5ps","outputId":"1267251c-617c-46a8-e3bb-a5afbdab3705"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final MCC Score","metadata":{"id":"62ZhnNVnkYqN"}},{"cell_type":"code","source":"predx = np.concatenate(preds, axis = 0)\npredm = np.argmax(predx, axis = 1).flatten()\n\nlabelm = np.concatenate(tl, axis = 0)\n\nfinal_mcc = matthews_corrcoef(labelm, predm)\nprint('The Final MCC Score is {}'.format(final_mcc))","metadata":{"id":"nrHdwwNkkKCo","outputId":"dcff1057-a6e2-4b12-b42d-d6839b7d8f8d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Line Graph for Loss","metadata":{"id":"-6tEzEOWMKvT"}},{"cell_type":"code","source":"sns.set(style = 'darkgrid')\nsns.set(font_scale = 1.5)\nplt.rcParams['figure.figsize'] = (12, 6)\n\nplt.plot(statistics['Training Loss'], 'b-o', label = 'Training Loss')\nplt.plot(statistics['Validation Loss'], 'g-o', label = 'Validation Loss')\n\nplt.title('Performance Visualization - Loss')\nplt.xlabel('#Epochs')\nplt.ylabel('Loss')\nplt.xticks(statistics.index, statistics.index + 1)\nplt.legend()\n\nplt.show()","metadata":{"id":"hawEAUkIMUJs","outputId":"9309fcc0-fdd3-414e-907a-5fa0bbd94fc2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bar Plot for Accuracy","metadata":{"id":"M_XopoovKgTN"}},{"cell_type":"code","source":"bar_x = ['Validation Accuracy', 'Test Accuracy']\nbar_y = [val_acc, test_acc]\ndb = {'Accuracy' : bar_x, 'Percentage' : bar_y}\ndb = pd.DataFrame(db)\nsns.barplot(x = 'Accuracy', y = 'Percentage', hue = 'Accuracy', data = db, palette = \"husl\", dodge = False)\nplt.title('Performance Visualization - Accuracy')\nplt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=True, ncol=3)\nplt.show()","metadata":{"id":"zh7_IooY_PE3","outputId":"96955af9-5a25-4799-f2a6-150866dd337a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiple Pie Charts for Conditions Distributions per Drug","metadata":{"id":"fIk1laaEKFVD"}},{"cell_type":"code","source":"print(\"Drug <-- Conditions\")\n\nfor d in drugs:\n    df1 = df_test.loc[df_test[\"drugName\"] == d]\n    df1 = df1[\"condition\"].value_counts().rename_axis(\"condition\").reset_index(name=\"count\")\n\n    plt.pie(x = df1[\"count\"], labels = df1[\"condition\"], autopct = \"%1.1f%%\")\n    plt.title(d)\n    plt.show()","metadata":{"id":"W6QJyV46XFb5","outputId":"003090bc-41bd-4746-c3ab-fc2021279a74"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiple Heatmaps for Drug Reccomendation based on Conditions","metadata":{"id":"Vo6S5p6KKWHE"}},{"cell_type":"code","source":"print(\"Drug <-- Conditions <-- Reccomend (Yes / No)\")\n\nfor d in drugs:\n    df2 = df_test.loc[df_test[\"drugName\"] == d]\n    conditions = df2[\"condition\"].unique()\n\n    Yes = []\n    No = []\n\n    for c in conditions:\n        df3 = df2.loc[df2[\"condition\"] == c]\n        dict3 = df3[\"rating\"].value_counts().to_dict()\n        y = dict3.get(1, 0)\n        n = dict3.get(0, 0)\n        Yes.append(y)\n        No.append(n)\n\n    classes = ['Reccomend', 'Do Not Reccomend']\n    vals = np.column_stack((Yes, No))\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(vals, cmap=\"Dark2\")\n    ax.grid(False)\n\n    ax.set_xticks(np.arange(len(classes)))\n    ax.set_yticks(np.arange(len(conditions)))\n\n    ax.set_xticklabels(classes)\n    ax.set_yticklabels(conditions)\n\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    for i in range(len(conditions)):\n        for j in range(len(classes)):\n            text = ax.text(j, i, \n                           vals[i, j],ha=\"center\", \n                           va=\"center\",color=\"w\", \n                           fontweight = \"bold\", fontsize = 15)\n\n    ax.set_title(d)\n    fig.tight_layout()\n    plt.show()","metadata":{"id":"16-WQZ7-o0XJ","outputId":"95761fc4-9115-4144-9a6d-50976b4c8c95"},"execution_count":null,"outputs":[]}]}